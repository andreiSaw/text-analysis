{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%pylab inline\n",
    "%precision 6\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import json\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth=100\n",
    "np.set_printoptions(linewidth=140,edgeitems=10)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "rcParams['figure.figsize'] = (8.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_lines=[]\n",
    "\n",
    "with open(\"tpc-dataset.train.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        json_lines.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame.from_dict(json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df_t=train_df\n",
    "df_t=df_t.sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>id</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>899434020</td>\n",
       "      <td>[Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "      <td>326894555</td>\n",
       "      <td>[Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>703031018</td>\n",
       "      <td>[Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age education         id                                                                                                texts\n",
       "0  18-24       NaN  899434020  [Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...\n",
       "1    NaN      high  326894555  [Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...\n",
       "2  18-24       NaN  703031018  [Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = { \"age\":       {\"<=17\": 1, \"18-24\": 2, \"25-34\":3, \"35-44\":4, \">=45\":5},\n",
    "                 \"education\": {\"low\": 1, \"middle\": 2,\"high\": 3} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.replace(cleanup_nums, inplace=True)\n",
    "df_t.education = df_t.education.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>id</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>899434020</td>\n",
       "      <td>[Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>326894555</td>\n",
       "      <td>[Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>703031018</td>\n",
       "      <td>[Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age education         id                                                                                                texts\n",
       "0  2.0         0  899434020  [Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...\n",
       "1  NaN         3  326894555  [Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...\n",
       "2  2.0         0  703031018  [Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.loc[:,'f'] = pd.Series(np.random.randn(len(df_t)), index=df_t.index)\n",
    "for index, row in df_t.iterrows():\n",
    "    df_t.at[index, 'f'] =len(df_t.at[index,'texts'])\n",
    "    df_t.at[index,'text']=''.join(df_t.at[index,'texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>texts</th>\n",
       "      <th>f</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-24</td>\n",
       "      <td>[Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Это уже все? Или можно вернуть?Владислав, а если розрабам написать?Владислав, за 1200-рублейПпц,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>СолнцеФорельВелосипедКонюховЛисСокЯмыФингалНизМясоЦариРогНораЛобНолик/ноликиИлСанкиСпар (на прав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-24</td>\n",
       "      <td>[Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?...</td>\n",
       "      <td>303.0</td>\n",
       "      <td>Aslan, девочки похлеще пацанов рубятся))Кристина, я тебя лайкнул,почему ты до сих пор не моя?😕Па...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y                                                                                                texts      f                                                                                                 text\n",
       "0  18-24  [Это уже все? Или можно вернуть?, Владислав, а если розрабам написать?, Владислав, за 1200-рубле...   37.0  Это уже все? Или можно вернуть?Владислав, а если розрабам написать?Владислав, за 1200-рублейПпц,...\n",
       "1    NaN  [Солнце, Форель, Велосипед, Конюхов, Лис, Сок, Ямы, Фингал, Низ, Мясо, Цари, Рог, Нора, Лоб, Нол...   33.0  СолнцеФорельВелосипедКонюховЛисСокЯмыФингалНизМясоЦариРогНораЛобНолик/ноликиИлСанкиСпар (на прав...\n",
       "2  18-24  [Aslan, девочки похлеще пацанов рубятся)), Кристина, я тебя лайкнул,почему ты до сих пор не моя?...  303.0  Aslan, девочки похлеще пацанов рубятся))Кристина, я тебя лайкнул,почему ты до сих пор не моя?😕Па..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z=df_t.drop([\"id\",\"education\"],axis=1)\n",
    "Z.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = df_t.apply(lambda x: pd.Series(x['texts']),axis=1).stack().reset_index(level=1, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.name = 'text'\n",
    "df_t.drop('texts', axis=1).join(s)\n",
    "df_t = df_t.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = df_t.set_index(['age', 'education',\"id\"])['texts'].apply(pd.Series).stack()\n",
    "res = res.reset_index()\n",
    "res.columns = ['age','education',\"id\",'text_num','text']\n",
    "Z = res.drop('text_num',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index, row in Z.iterrows():\n",
    "    Z.set_value(index, 'text', Z['text'][index].lower()\n",
    "                .replace('.', ' ')\n",
    "                .replace(',', ' ')\n",
    "                .replace(';', ' ')\n",
    "                .replace(':', ' ')\n",
    "                .replace('!', ' ')\n",
    "                .replace('?', ' ')\n",
    "                .replace('\\r', ' ')\n",
    "                .replace('\\n', ' ')\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8607"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.rename(columns={'age':'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       NaN\n",
       "2       2.0\n",
       "3       3.0\n",
       "4       NaN\n",
       "5       1.0\n",
       "6       3.0\n",
       "7       NaN\n",
       "8       NaN\n",
       "9       1.0\n",
       "10      5.0\n",
       "11      2.0\n",
       "12      4.0\n",
       "13      NaN\n",
       "14      1.0\n",
       "15      2.0\n",
       "16      NaN\n",
       "17      1.0\n",
       "18      1.0\n",
       "19      NaN\n",
       "20      2.0\n",
       "21      1.0\n",
       "22      NaN\n",
       "23      3.0\n",
       "24      3.0\n",
       "25      NaN\n",
       "26      3.0\n",
       "27      1.0\n",
       "28      NaN\n",
       "29      2.0\n",
       "30      1.0\n",
       "31      3.0\n",
       "32      NaN\n",
       "33      2.0\n",
       "34      NaN\n",
       "35      3.0\n",
       "36      2.0\n",
       "37      3.0\n",
       "38      2.0\n",
       "39      2.0\n",
       "40      3.0\n",
       "41      3.0\n",
       "42      2.0\n",
       "43      NaN\n",
       "44      3.0\n",
       "45      4.0\n",
       "46      NaN\n",
       "47      1.0\n",
       "48      3.0\n",
       "49      NaN\n",
       "50      1.0\n",
       "51      NaN\n",
       "52      2.0\n",
       "53      2.0\n",
       "54      1.0\n",
       "55      3.0\n",
       "56      NaN\n",
       "57      1.0\n",
       "58      3.0\n",
       "59      NaN\n",
       "60      1.0\n",
       "61      4.0\n",
       "62      3.0\n",
       "63      1.0\n",
       "64      NaN\n",
       "65      2.0\n",
       "66      3.0\n",
       "67      2.0\n",
       "68      3.0\n",
       "69      1.0\n",
       "70      1.0\n",
       "71      3.0\n",
       "72      3.0\n",
       "73      1.0\n",
       "74      NaN\n",
       "75      3.0\n",
       "76      1.0\n",
       "77      5.0\n",
       "78      3.0\n",
       "79      3.0\n",
       "80      1.0\n",
       "81      3.0\n",
       "82      3.0\n",
       "83      3.0\n",
       "84      NaN\n",
       "85      4.0\n",
       "86      3.0\n",
       "87      1.0\n",
       "88      NaN\n",
       "89      3.0\n",
       "90      1.0\n",
       "91      3.0\n",
       "92      1.0\n",
       "93      1.0\n",
       "94      4.0\n",
       "95      2.0\n",
       "96      3.0\n",
       "97      3.0\n",
       "98      2.0\n",
       "99      NaN\n",
       "100     1.0\n",
       "101     4.0\n",
       "102     1.0\n",
       "103     1.0\n",
       "104     2.0\n",
       "105     3.0\n",
       "106     4.0\n",
       "107     4.0\n",
       "108     2.0\n",
       "109     NaN\n",
       "110     NaN\n",
       "111     5.0\n",
       "112     4.0\n",
       "113     NaN\n",
       "114     2.0\n",
       "115     NaN\n",
       "116     1.0\n",
       "117     3.0\n",
       "118     NaN\n",
       "119     2.0\n",
       "120     2.0\n",
       "121     1.0\n",
       "122     1.0\n",
       "123     2.0\n",
       "124     3.0\n",
       "125     NaN\n",
       "126     NaN\n",
       "127     1.0\n",
       "128     2.0\n",
       "129     5.0\n",
       "130     1.0\n",
       "131     1.0\n",
       "132     1.0\n",
       "133     1.0\n",
       "134     1.0\n",
       "135     1.0\n",
       "136     NaN\n",
       "137     NaN\n",
       "138     NaN\n",
       "139     1.0\n",
       "140     3.0\n",
       "141     3.0\n",
       "142     2.0\n",
       "143     NaN\n",
       "144     NaN\n",
       "145     2.0\n",
       "146     1.0\n",
       "147     2.0\n",
       "148     NaN\n",
       "149     2.0\n",
       "150     2.0\n",
       "151     4.0\n",
       "152     3.0\n",
       "153     3.0\n",
       "154     2.0\n",
       "155     3.0\n",
       "156     4.0\n",
       "157     2.0\n",
       "158     1.0\n",
       "159     NaN\n",
       "160     2.0\n",
       "161     3.0\n",
       "162     1.0\n",
       "163     1.0\n",
       "164     3.0\n",
       "165     NaN\n",
       "166     2.0\n",
       "167     3.0\n",
       "168     NaN\n",
       "169     5.0\n",
       "170     NaN\n",
       "171     1.0\n",
       "172     4.0\n",
       "173     1.0\n",
       "174     2.0\n",
       "175     3.0\n",
       "176     2.0\n",
       "177     1.0\n",
       "178     2.0\n",
       "179     5.0\n",
       "180     2.0\n",
       "181     1.0\n",
       "182     2.0\n",
       "183     2.0\n",
       "184     2.0\n",
       "185     2.0\n",
       "186     NaN\n",
       "187     5.0\n",
       "188     1.0\n",
       "189     NaN\n",
       "190     1.0\n",
       "191     2.0\n",
       "192     1.0\n",
       "193     NaN\n",
       "194     1.0\n",
       "195     NaN\n",
       "196     3.0\n",
       "197     1.0\n",
       "198     3.0\n",
       "199     2.0\n",
       "200     1.0\n",
       "201     3.0\n",
       "202     2.0\n",
       "203     NaN\n",
       "204     3.0\n",
       "205     1.0\n",
       "206     1.0\n",
       "207     NaN\n",
       "208     2.0\n",
       "209     1.0\n",
       "210     3.0\n",
       "211     NaN\n",
       "212     4.0\n",
       "213     3.0\n",
       "214     NaN\n",
       "215     NaN\n",
       "216     3.0\n",
       "217     3.0\n",
       "218     2.0\n",
       "219     3.0\n",
       "220     2.0\n",
       "221     5.0\n",
       "222     NaN\n",
       "223     3.0\n",
       "224     NaN\n",
       "225     1.0\n",
       "226     2.0\n",
       "227     1.0\n",
       "228     NaN\n",
       "229     2.0\n",
       "230     NaN\n",
       "231     1.0\n",
       "232     NaN\n",
       "233     1.0\n",
       "234     2.0\n",
       "235     NaN\n",
       "236     NaN\n",
       "237     3.0\n",
       "238     NaN\n",
       "239     NaN\n",
       "240     NaN\n",
       "241     3.0\n",
       "242     NaN\n",
       "243     4.0\n",
       "244     2.0\n",
       "245     2.0\n",
       "246     3.0\n",
       "247     1.0\n",
       "248     3.0\n",
       "249     NaN\n",
       "       ... \n",
       "8357    3.0\n",
       "8358    4.0\n",
       "8359    5.0\n",
       "8360    NaN\n",
       "8361    3.0\n",
       "8362    2.0\n",
       "8363    NaN\n",
       "8364    3.0\n",
       "8365    2.0\n",
       "8366    3.0\n",
       "8367    NaN\n",
       "8368    3.0\n",
       "8369    2.0\n",
       "8370    NaN\n",
       "8371    2.0\n",
       "8372    NaN\n",
       "8373    1.0\n",
       "8374    3.0\n",
       "8375    4.0\n",
       "8376    1.0\n",
       "8377    4.0\n",
       "8378    NaN\n",
       "8379    3.0\n",
       "8380    2.0\n",
       "8381    NaN\n",
       "8382    3.0\n",
       "8383    5.0\n",
       "8384    1.0\n",
       "8385    NaN\n",
       "8386    NaN\n",
       "8387    NaN\n",
       "8388    2.0\n",
       "8389    1.0\n",
       "8390    NaN\n",
       "8391    4.0\n",
       "8392    NaN\n",
       "8393    1.0\n",
       "8394    1.0\n",
       "8395    3.0\n",
       "8396    3.0\n",
       "8397    3.0\n",
       "8398    2.0\n",
       "8399    2.0\n",
       "8400    3.0\n",
       "8401    3.0\n",
       "8402    1.0\n",
       "8403    NaN\n",
       "8404    2.0\n",
       "8405    1.0\n",
       "8406    2.0\n",
       "8407    3.0\n",
       "8408    3.0\n",
       "8409    2.0\n",
       "8410    1.0\n",
       "8411    2.0\n",
       "8412    NaN\n",
       "8413    4.0\n",
       "8414    2.0\n",
       "8415    3.0\n",
       "8416    3.0\n",
       "8417    3.0\n",
       "8418    NaN\n",
       "8419    1.0\n",
       "8420    3.0\n",
       "8421    2.0\n",
       "8422    2.0\n",
       "8423    2.0\n",
       "8424    2.0\n",
       "8425    1.0\n",
       "8426    1.0\n",
       "8427    3.0\n",
       "8428    NaN\n",
       "8429    1.0\n",
       "8430    3.0\n",
       "8431    1.0\n",
       "8432    3.0\n",
       "8433    1.0\n",
       "8434    2.0\n",
       "8435    2.0\n",
       "8436    2.0\n",
       "8437    1.0\n",
       "8438    4.0\n",
       "8439    1.0\n",
       "8440    3.0\n",
       "8441    NaN\n",
       "8442    3.0\n",
       "8443    3.0\n",
       "8444    1.0\n",
       "8445    2.0\n",
       "8446    3.0\n",
       "8447    3.0\n",
       "8448    4.0\n",
       "8449    4.0\n",
       "8450    1.0\n",
       "8451    2.0\n",
       "8452    1.0\n",
       "8453    NaN\n",
       "8454    3.0\n",
       "8455    2.0\n",
       "8456    2.0\n",
       "8457    1.0\n",
       "8458    3.0\n",
       "8459    4.0\n",
       "8460    2.0\n",
       "8461    NaN\n",
       "8462    1.0\n",
       "8463    NaN\n",
       "8464    NaN\n",
       "8465    1.0\n",
       "8466    1.0\n",
       "8467    5.0\n",
       "8468    3.0\n",
       "8469    2.0\n",
       "8470    3.0\n",
       "8471    3.0\n",
       "8472    3.0\n",
       "8473    3.0\n",
       "8474    3.0\n",
       "8475    3.0\n",
       "8476    4.0\n",
       "8477    1.0\n",
       "8478    2.0\n",
       "8479    3.0\n",
       "8480    3.0\n",
       "8481    4.0\n",
       "8482    1.0\n",
       "8483    5.0\n",
       "8484    3.0\n",
       "8485    3.0\n",
       "8486    4.0\n",
       "8487    3.0\n",
       "8488    1.0\n",
       "8489    1.0\n",
       "8490    2.0\n",
       "8491    1.0\n",
       "8492    1.0\n",
       "8493    NaN\n",
       "8494    NaN\n",
       "8495    2.0\n",
       "8496    NaN\n",
       "8497    NaN\n",
       "8498    NaN\n",
       "8499    1.0\n",
       "8500    NaN\n",
       "8501    1.0\n",
       "8502    1.0\n",
       "8503    1.0\n",
       "8504    3.0\n",
       "8505    2.0\n",
       "8506    NaN\n",
       "8507    1.0\n",
       "8508    3.0\n",
       "8509    2.0\n",
       "8510    1.0\n",
       "8511    NaN\n",
       "8512    NaN\n",
       "8513    1.0\n",
       "8514    3.0\n",
       "8515    3.0\n",
       "8516    1.0\n",
       "8517    NaN\n",
       "8518    NaN\n",
       "8519    NaN\n",
       "8520    3.0\n",
       "8521    4.0\n",
       "8522    1.0\n",
       "8523    NaN\n",
       "8524    2.0\n",
       "8525    NaN\n",
       "8526    NaN\n",
       "8527    1.0\n",
       "8528    NaN\n",
       "8529    1.0\n",
       "8530    1.0\n",
       "8531    1.0\n",
       "8532    2.0\n",
       "8533    NaN\n",
       "8534    2.0\n",
       "8535    4.0\n",
       "8536    2.0\n",
       "8537    1.0\n",
       "8538    3.0\n",
       "8539    3.0\n",
       "8540    NaN\n",
       "8541    NaN\n",
       "8542    NaN\n",
       "8543    4.0\n",
       "8544    1.0\n",
       "8545    1.0\n",
       "8546    2.0\n",
       "8547    NaN\n",
       "8548    2.0\n",
       "8549    1.0\n",
       "8550    NaN\n",
       "8551    5.0\n",
       "8552    2.0\n",
       "8553    NaN\n",
       "8554    1.0\n",
       "8555    4.0\n",
       "8556    3.0\n",
       "8557    2.0\n",
       "8558    2.0\n",
       "8559    NaN\n",
       "8560    1.0\n",
       "8561    3.0\n",
       "8562    3.0\n",
       "8563    1.0\n",
       "8564    2.0\n",
       "8565    2.0\n",
       "8566    NaN\n",
       "8567    1.0\n",
       "8568    3.0\n",
       "8569    NaN\n",
       "8570    2.0\n",
       "8571    2.0\n",
       "8572    NaN\n",
       "8573    2.0\n",
       "8574    1.0\n",
       "8575    1.0\n",
       "8576    NaN\n",
       "8577    2.0\n",
       "8578    3.0\n",
       "8579    4.0\n",
       "8580    1.0\n",
       "8581    NaN\n",
       "8582    2.0\n",
       "8583    NaN\n",
       "8584    4.0\n",
       "8585    3.0\n",
       "8586    NaN\n",
       "8587    2.0\n",
       "8588    2.0\n",
       "8589    2.0\n",
       "8590    1.0\n",
       "8591    NaN\n",
       "8592    3.0\n",
       "8593    2.0\n",
       "8594    4.0\n",
       "8595    NaN\n",
       "8596    2.0\n",
       "8597    2.0\n",
       "8598    3.0\n",
       "8599    1.0\n",
       "8600    NaN\n",
       "8601    3.0\n",
       "8602    1.0\n",
       "8603    NaN\n",
       "8604    3.0\n",
       "8605    1.0\n",
       "8606    3.0\n",
       "Name: y, Length: 8607, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sels = ~isnan(Z.y)\n",
    "test_sels = isnan(Z.y)\n",
    "\n",
    "train_inds = find(train_sels)\n",
    "test_inds = find(test_sels)\n",
    "\n",
    "del train_sels, test_sels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Z.text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "Y=Z.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8607, 8607)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0], len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest\n",
      "OOB Score = 0.463456712673\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest or bagged tree based the model chosen\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "rfc = RFC(n_estimators = 100, oob_score = True, max_features = \"auto\")\n",
    "print (\"Training %s\" % (\"Random Forest\"))\n",
    "rfc = rfc.fit(X[train_inds], Y[train_inds])\n",
    "print (\"OOB Score =\", rfc.oob_score_)\n",
    "pred = rfc.predict(X[test_inds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"age\":{ 1:\"<=17\", 2:\"18-24\", 3:\"25-34\", 4:\"35-44\", 5:\">=45\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {\"id\":test_inds , \"age\": pred})\n",
    "output.replace(cleanup_nums, inplace=True)\n",
    "output.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "clf = sklearn.model_selection.GridSearchCV(sklearn.svm.LinearSVC() ,param_grid, n_jobs=-1) # use n_jobs=1 here if have insufficient memory\n",
    "clf.fit(X[train_inds], Y[train_inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = clf.predict(X[test_inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = concatenate([Z['id'][test_inds].values[:,newaxis], Y_hat[:,newaxis]],axis=1)\n",
    "content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame( content, columns = ['ReviewId', 'Score'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv('d1 solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model100=fasttext.load_model(\"fasttext100.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
